# ğŸ“¡ Web Scraper Backend â€“ Go + Colly + MySQL + Docker + Goose

[![Go Version](https://img.shields.io/badge/Go-1.25+-00ADD8?logo=go&logoColor=white)](https://golang.org)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white)](https://docker.com)
[![MySQL](https://img.shields.io/badge/MySQL-8.0-4479A1?logo=mysql&logoColor=white)](https://mysql.com)
[![Status](https://img.shields.io/badge/Production_Ready-Yes-brightgreen)]()

Sistema de **scraping backend profesional**, construido con:

âœ… **Golang**  
âœ… **Colly (sin navegador)**  
âœ… **Login automÃ¡tico con CSRF y cookies**  
âœ… **Worker Pool concurrente**  
âœ… **MySQL con migraciones Goose**  
âœ… **Docker y Docker Compose**

El scraper ingresa al portal **UberSmith/Billing**, obtiene el reporte diario, parsea la tabla HTML y guarda los registros en MySQL.

---

# ğŸ“‘ Ãndice

- [ğŸ“Œ DescripciÃ³n General](#-descripciÃ³n-general)
- [ğŸ“ Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ— Arquitectura del Sistema](#-arquitectura-del-sistema)
- [âš™ï¸ ConfiguraciÃ³n del Entorno](#ï¸-configuraciÃ³n-del-entorno)
- [ğŸ³ EjecuciÃ³n con Docker](#-ejecuciÃ³n-con-docker)
- [ğŸ§  DiseÃ±o del Scraper](#-diseÃ±o-del-scraper)
- [ğŸ›¢ Modelo de Datos](#-modelo-de-datos)
- [ğŸ“œ Migraciones Goose](#-migraciones-goose)
- [ğŸ§ª Pruebas y VerificaciÃ³n](#-pruebas-y-verificaciÃ³n)
- [ğŸš¨ Troubleshooting](#-troubleshooting)

---

# ğŸ“Œ DescripciÃ³n General

Este proyecto implementa un web scraper backend desarrollado en Golang, utilizando la librerÃ­a Colly para realizar scraping sin navegador (HTTP puro) y GORM para gestionar la persistencia en una base de datos MySQL.

El sistema estÃ¡ completamente dockerizado, lo que permite su ejecuciÃ³n en cualquier entorno sin necesidad de instalaciones adicionales.

1. Login en **billing.osnetpr.com**
2. ObtenciÃ³n de tokens **CSRF dinÃ¡micos**
3. Reescritura correcta de cookies `PHPSESSID`
4. Scraping de tabla HTML estructurada
5. ExtracciÃ³n de campos seleccionados:
   - ClientID  
   - Client  
   - Date  
   - Type  
   - Amount  
   - Agent  
6. Inserciones en MySQL mediante un **worker pool concurrente**
7. Migraciones automÃ¡ticas antes de ejecutar la app

Todo funciona desde backend, sin navegador, usando Ãºnicamente **HTTP/HTML parsing con Colly**.

---

# ğŸ“ Estructura del Proyecto

go-colly-mysql/
â”œâ”€â”€ cmd/
â”‚ â””â”€â”€ scraper/main.go
â”œâ”€â”€ internal/
â”‚ â”œâ”€â”€ db/db.go
â”‚ â”œâ”€â”€ model/record.go
â”‚ â””â”€â”€ scraper/
â”‚ â”œâ”€â”€ login.go
â”‚ â””â”€â”€ scraper.go
â”œâ”€â”€ migrations/
â”‚ â”œâ”€â”€ 2025..._init_schema.sql
â”‚ â”œâ”€â”€ 2025..._alter_records_columns.sql
â”‚ â””â”€â”€ 2025..._add_indexes.sql
| â”œâ”€â”€ 2025..._change_date_to_datetime
â”‚ â””â”€â”€ 2025..._change_amount_to_decimal
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ dockerfile
â”œâ”€â”€ entrypoint.sh
â”œâ”€â”€ goose-db.yaml
â”œâ”€â”€ .env
â””â”€â”€ README.md

---

# ğŸ— Arquitectura del Sistema

Â´Â´Â´mermaid
flowchart TD

A[Arranque Docker] --> B[MySQL inicia y pasa healthcheck]
B --> C[entrypoint.sh]
C --> D[Goose ejecuta migraciones]
D --> E[Lanzar binario scraper]

E --> F[InitCollector()]
F --> G[Login() -> CSRF + Cookies]
G --> H[ConstrucciÃ³n URL con timestamps]

H --> I[RunScrape()]
I --> J[Parseo de tabla HTML]
J --> K[Worker Pool]
K --> L[InserciÃ³n MySQL]
L --> M[Finaliza ejecuciÃ³n]

---

# âš™ï¸ ConfiguraciÃ³n del Entorno

1) .env
 Credenciales de la pagina de login
BILLING_USER=usuario_demo
BILLING_PASS=pass_demo

 Horario de ejecuciÃ³n del scraper
TIMEZONE=America/Puerto_Rico
SCRAPER_HOUR=HORA_EJECUCION_0-23
SCRAPER_MINUTE=MINUTO_EJECUCION_0-59

2) docker-compose
DB_HOST=mysql
DB_PORT=3306
DB_USER=app
DB_PASSWORD=apppass
DB_NAME=appdb

TARGET_URL=https://billing.osnetpr.com/admin/reports/report_billings_detail.php?type=&begin=%d&end=%d&type=
TABLE_SELECTOR=table.table-body-modern
ROW_SELECTOR=tr

---

# ğŸ³ EjecuciÃ³n con Docker

Ejecutar: docker compose up --build

El proceso:

âœ… 1. MySQL inicia con healthcheck
âœ… 2. Goose aplica migraciones
âœ… 3. Se lanza /root/scraper
âœ… 4. El login automÃ¡tico se ejecuta
âœ… 5. Se obtiene el reporte del dÃ­a
âœ… 6. Se parsean filas y se insertan en la BD

Logs: docker logs -f app

---

# ğŸ§  DiseÃ±o del Scraper
âœ… Login (login.go)

Se hace GET inicial al portal

Se extraen csrf_key y csrf_token desde los <script>

Se envÃ­a POST completo

Se verifica cookie PHPSESSID

Se reescribe cookie â†’ dominio raÃ­z (billing.osnetpr.com)

Esto permite mantener la sesiÃ³n en cualquier subruta del portal.

ğŸ›  RunScrape (scraper.go)

Detecta tabla vÃ­a TABLE_SELECTOR

Recorre tr de la tabla

Extrae columnas:
td[1] â†’ ClientID
td[2] â†’ Client
td[3] â†’ Date
td[6] â†’ Type
td[9] â†’ Amount
td[12] â†’ Agent

EnvÃ­a cada registro a un canal bufferizado (200)

Worker pool de 5 goroutines inserta en MySQL

---

# ğŸ›¢ Modelo de Datos
Archivo: internal/model/record.go
type Record struct {
    gorm.Model
    ClientID string
    Client   string
    Date     string
    Type     string
    Amount   string
    Agent    string
}

---

# ğŸ“œ Migraciones Goose

Migraciones en /migrations:

âœ… init_schema.sql
Crea tabla records.

âœ… alter_records_columns.sql
Ajusta tamaÃ±os de columnas.

âœ… add_indexes.sql
AÃ±ade Ã­ndices para acelerar consultas.

âœ… change_date_to_datetime
Cambia el tipo de dato a date

âœ… change_amount_to_decimal
Cambia el tipo de dato decimal

Se ejecutan automÃ¡ticamente por: entrypoint.sh â†’ goose up

---

# ğŸ§ª Pruebas y VerificaciÃ³n
âœ… Entrar al contenedor MySQL
docker exec -it scraper-mysql-1 mysql -uapp -papppass appdb

âœ… Ver datos insertados
SELECT * FROM records;

âœ… Ver errores desde el worker pool
docker logs -f app

---

# ğŸš¨ Troubleshooting
âŒ Error: no se encuentra PHPSESSID despuÃ©s del POST

Revisar credenciales en .env

Portal pudo haber cambiado CSRF

Ver logs de csrf_key y csrf_token

âŒ Tabla no encontrada

Goose no ejecutÃ³ migraciones â†’ verificar: docker compose logs app

âŒ Scraping devuelve filas vacÃ­as

Revisar TABLE_SELECTOR

Revisar Ã­ndices td[x]

Ver pÃ¡gina HTML real usando: docker exec -it app sh
curl <URL>


